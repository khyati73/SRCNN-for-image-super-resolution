# -*- coding: utf-8 -*-
"""SRCNN_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eDYxrl3UvdbtEZlBYXepzoYqXijWA6dw
"""

import keras.backend as K
from keras.models import Sequential, Model
from keras.layers import Dense, Conv2D, Activation, Input
from keras import optimizers
from keras.models import load_model
import numpy as np
import scipy.misc
import imageio
import scipy.ndimage
import cv2
import math
import glob
import matplotlib.pyplot as plt
from skimage.metrics import structural_similarity as ssim

!unzip yang91.zip

img_shape = (32,32,1) #(None,None,1)
input_img = Input(shape=(img_shape))
#creating the architecture of srcnn model
ConvL1 = Conv2D(64,(9,9),padding='SAME',name='CONV1')(input_img)
ActivL1 = Activation('relu', name='act1')(ConvL1)
ConvL2 = Conv2D(32,(1,1),padding='SAME',name='CONV2')(ActivL1)
ActivL2 = Activation('relu', name='act2')(ConvL2)
ConvL3 = Conv2D(1,(5,5),padding='SAME',name='CONV3')(ActivL2)
ActivL3 = Activation('relu', name='act3')(ConvL3)
model = Model(input_img, ActivL3)
opt = optimizers.Adam(learning_rate=0.0003)
model.compile(optimizer=opt,loss='mean_squared_error')
model.summary()

def modcrop(image, scale=2): #SCALING BY SCALE FACTOR OF 2
    if len(image.shape) == 3:
        h, w, _ = image.shape
        h = h - np.mod(h, scale)
        w = w - np.mod(w, scale)
        image = image[0:h, 0:w, :]
    else:
        h, w = image.shape
        h = h - np.mod(h, scale)
        w = w - np.mod(w, scale)
        image = image[0:h, 0:w]
    return image

def create_LR(image,scale):     #function to create low resolution images
    label_ = modcrop(image, scale)
    label_ = label_ / 255.
    input_ = scipy.ndimage.interpolation.zoom(label_, (1./scale), prefilter=False)
    input_ = scipy.ndimage.interpolation.zoom(input_, (scale/1.), prefilter=False)
    return input_

path = 'yang91/'
files_y = glob.glob(path + '*.*')
trainfiles = files_y[:60]             #THE DATASET HAS TOTAL IMAGES = 91 , So images up to 85 used for Training
valfiles = files_y[60:]               #Above 85 are used for Validation Set
img_size = 32
stride = 16
X_train = []
Y_train = []
X_val = []
Y_val = []

# Extract patch image for training
for file_y in trainfiles:
    tmp_y = imageio.imread(file_y, as_gray=True, pilmode='YCbCr').astype(np.float)
    tmp_X = create_LR(tmp_y,2)
    
    h,w = tmp_y.shape
    for x in range(0, h-img_size+1, stride):
        for y in range(0, w-img_size+1, stride):
            sub_input = tmp_X[x:x+img_size,y:y+img_size].reshape(img_size,img_size,1)
            sub_label = tmp_y[x:x+img_size, y:y+img_size].reshape(img_size,img_size,1)
            X_train.append(sub_input)
            Y_train.append(sub_label)

# Extract patch image for validation
for file_y in valfiles:
    tmp_y = imageio.imread(file_y, as_gray=True, pilmode='YCbCr').astype(np.float)
    tmp_X = create_LR(tmp_y,2)  
    
    h,w = tmp_y.shape
    for x in range(0, h-img_size+1, stride):
        for y in range(0, w-img_size+1, stride):
            sub_input = tmp_X[x:x+img_size,  y:y+img_size].reshape(img_size,img_size,1) # [32 x 32]
            sub_label = tmp_y[x:x+img_size, y:y+img_size].reshape(img_size,img_size,1) # [32 x 32]
            X_val.append(sub_input)
            Y_val.append(sub_label)

X_train = np.array(X_train)
Y_train = np.array(Y_train)
X_val = np.array(X_val)
Y_val = np.array(Y_val)

LEARN_RATE = 0.0003

from keras.callbacks import ModelCheckpoint
from keras.optimizers import Adam, SGD

checkpoint = ModelCheckpoint('best_model_improved.h5',  # model filename
                             monitor='val_loss',    # quantity to monitor
                             verbose=0,             # verbosity - 0 or 1
                             save_best_only= True,  # The latest best model will not be overwritten
                             mode='auto')           # The decision to overwrite model is made automatically depending on the quantity to monitor

"""Initially, we will have an input of a image. We are required to know the quality of the image in order to proceed further. For this, we'll make use of Quantitative metrics. We can use multiple methods for this, like 'Peak signal to noise ratio' or 'Mean sqaured error'. The research paper referred for our project suggests the use of MSE."""

def mse(target, ref):
#our target is a RGB image
    target_data = target.astype(np.float32)
    ref_data = ref.astype(np.float32)
    err = np.sum((target_data - ref_data) ** 2)
    
    err /= np.float(target_data.shape[0] * target_data.shape[1])
    return err

model.compile(loss='mse', # Better loss function for neural networks
              optimizer=Adam(learning_rate=LEARN_RATE),) # Adam optimizer with 0.0003 learning rate)

model_details = model.fit(X_train, Y_train,
                    batch_size = 128,
                    epochs = 50, # number of iterations
                    validation_data= (X_val, Y_val),
                    callbacks=[checkpoint],
                    verbose=1)

scores = model.evaluate(X_val, Y_val, verbose=0)
print("LOSS: %.2f%%" % (scores))

#from tensorflow.keras.models import Sequential, save_model, load_model

model.save('wscale2.h5')

img_o = imageio.imread('baby_x2_GT.png', as_gray=True,pilmode='YCbCr').astype(np.float)
img = create_LR(img_o,2) #Scaling
img_size = 32
stride = 16
h,w = img.shape
piece_wise = []
for x in range(0, h-img_size+1, stride):
    for y in range (0, w-img_size+1, stride):
        sub_input = img[x:x+img_size, y:y+img_size].reshape(img_size,img_size,1)
        piece_wise.append(sub_input)
input_ = np.asarray(piece_wise)
srcnn = load_model('wscale2.h5')
hat = srcnn.predict(input_)
img_re = np.zeros(img.shape)
i = 0
for x in range(0, h-img_size+1, stride):
    for y in range (0, w-img_size+1, stride):
        img_re[x:x+img_size, y:y+img_size] = hat[i].reshape(img_size,img_size)
        i += 1
cv2.imwrite('restored1.bmp', img_re)
cv2.imwrite('HR1.bmp', img_o)
img_save = (img*255).astype(np.uint8)
cv2.imwrite('blurred1.bmp',img_save)

#CALCULATE PSNR
original = cv2.imread("HR1.bmp")
LR       = cv2.imread("blurred1.bmp")
contrast = cv2.imread("restored1.bmp",1)
def psnr(img1, img2):
    mse = np.mean((img1-img2)**2)
    if mse ==0:
        return 100
    PIXEL_MAX = 255.0
    return 20* math.log10(PIXEL_MAX / math.sqrt(mse))
d = psnr(original,contrast)
print(d)

fig = plt.figure(figsize = (14,14), dpi = 100)
ax = plt.subplot("131")
ax.imshow(original)
ax.set_title("Original")
plt.grid(0)

ax = plt.subplot("132")
ax.imshow(LR)
ax.set_title("blurred_Image")
plt.grid(0)

ax = plt.subplot("133")
ax.imshow(contrast)
ax.set_title("HR_RECONSTRUCTED")
plt.grid(0)
plt.show()

from skimage.metrics import structural_similarity as ssim

def compare_images(target, ref):
    scores = []
    scores.append(psnr(target, ref))
    scores.append(mse(target, ref))
    scores.append(ssim(target, ref, multichannel=True))
    return scores

# Comparing original and predicted image
metrics = compare_images(original, contrast)
print("Metrics for original and predicted image")
print("PSNR: {}".format(metrics[0]))
print("MSE: {}".format(metrics[1]))
print("SSIM: {}".format(metrics[2]))
